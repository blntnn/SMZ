{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1702066165861,
     "user": {
      "displayName": "Adlisse",
      "userId": "09888939323989321551"
     },
     "user_tz": -180
    },
    "id": "3lghA00s9EVj"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn.functional import conv2d as libConv2d\n",
    "from torch.nn.functional import conv_transpose2d as libConv2dT\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1702066166207,
     "user": {
      "displayName": "Adlisse",
      "userId": "09888939323989321551"
     },
     "user_tz": -180
    },
    "id": "ZMx8XjXR9EVy"
   },
   "outputs": [],
   "source": [
    "def custom_conv_transpose(matrix, \n",
    "                          in_channels, \n",
    "                          out_channels, \n",
    "                          kernel_size,\n",
    "                          stride=1, \n",
    "                          padding=0, \n",
    "                          output_padding=0, \n",
    "                          dilation=1,\n",
    "                          bias=True, \n",
    "                          padding_mode='zeros'):\n",
    "    if bias:\n",
    "        bias_val = torch.rand(out_channels) \n",
    "    else:\n",
    "        bias_val = torch.zeros(out_channels)\n",
    "\n",
    "    if type(kernel_size) == int:\n",
    "        weights = torch.rand(in_channels, out_channels, kernel_size, kernel_size)  \n",
    "    else:\n",
    "        weights = torch.rand(in_channels, out_channels, *kernel_size)\n",
    "    res_tensor = []\n",
    "    for l in range(out_channels):\n",
    "        feature_map = torch.zeros((matrix.shape[1] - 1) * stride + dilation * (kernel_size - 1) + 1,\n",
    "                                  (matrix.shape[2] - 1) * stride + dilation * (kernel_size - 1) + 1)\n",
    "\n",
    "        for c in range(in_channels):\n",
    "            for i in range(0, matrix.shape[1]):\n",
    "                for j in range(0, matrix.shape[2]):\n",
    "                    val = matrix[c][i][j]\n",
    "                    proizv = val * weights[c][l]\n",
    "                    zero_tensor = torch.zeros((weights.shape[2] - 1) * dilation + 1,\n",
    "                                              (weights.shape[3] - 1) * dilation + 1)\n",
    "                    for a in range(0, zero_tensor.shape[0], dilation):\n",
    "                        for b in range(0, zero_tensor.shape[1], dilation):\n",
    "                            zero_tensor[a][b] = proizv[a // dilation][b // dilation]\n",
    "                    res = np.add(zero_tensor, feature_map[i * stride:i * stride + (weights.shape[2] - 1) * dilation + 1,\n",
    "                                 j * stride:j * stride + (weights.shape[3] - 1) * dilation + 1])\n",
    "                    feature_map[i * stride:i * stride + (weights.shape[2] - 1) * dilation + 1,\n",
    "                    j * stride:j * stride + (weights.shape[3] - 1) * dilation + 1] = res\n",
    "\n",
    "        res_tensor.append(np.add(feature_map, np.full(feature_map.shape, bias_val[l])))\n",
    "\n",
    "    for t in range(len(res_tensor)):\n",
    "        if output_padding > 0:\n",
    "            pad_func = torch.nn.ConstantPad1d((0, output_padding, 0, output_padding), 0)\n",
    "            res_tensor[t] = pad_func(res_tensor[t])\n",
    "\n",
    "        res_tensor[t] = res_tensor[t][0 + padding:res_tensor[t].shape[0] - padding,\n",
    "                                      0 + padding:res_tensor[t].shape[1] - padding]\n",
    "\n",
    "    return res_tensor, weights, torch.tensor(bias_val)\n",
    "\n",
    "def compare_results(tensor, in_channels, out_channels, kernel_size, stride, padding, output_padding, dilation, bias=True, padding_mode='zeros'):\n",
    "    my_res, kernel, bias_val = custom_conv_transpose(\n",
    "        tensor,\n",
    "        in_channels=in_channels, out_channels=out_channels,\n",
    "        kernel_size=kernel_size, stride=stride,\n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias,\n",
    "        padding_mode=padding_mode,\n",
    "    )\n",
    "\n",
    "    torch_function = torch.nn.ConvTranspose2d(\n",
    "        in_channels=in_channels, out_channels=out_channels,\n",
    "        kernel_size=kernel_size, stride=stride,\n",
    "        padding=padding, output_padding=output_padding,\n",
    "        dilation=dilation, bias=bias,\n",
    "        padding_mode=padding_mode,\n",
    "    )\n",
    "    torch_function.weight.data = kernel\n",
    "    torch_function.bias.data = bias_val\n",
    "\n",
    "    result = str(np.round([tensor.tolist() for tensor in my_res], 2))\n",
    "    torch_res = str(np.round(torch_function(tensor).data.numpy(), 2))\n",
    "    return result == torch_res\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверяем работоспособность функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1702066926975,
     "user": {
      "displayName": "Adlisse",
      "userId": "09888939323989321551"
     },
     "user_tz": -180
    },
    "id": "bwNHtrEk9EV1",
    "outputId": "a6b15914-9f3b-4f61-bd3b-f104247a3cb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "tensor1 = torch.rand(8, 5, 6)\n",
    "print(compare_results(tensor1, in_channels=8, out_channels=2, kernel_size=3, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros'))\n",
    "\n",
    "tensor2 = torch.rand(3, 28, 28)\n",
    "print(compare_results(tensor2, in_channels=3, out_channels=2, kernel_size=3, stride=10, padding=0, output_padding=0, dilation=3, bias=True, padding_mode='zeros'))\n",
    "\n",
    "tensor3 = torch.rand(5, 6, 6)\n",
    "print(compare_results(tensor3, in_channels=5, out_channels=1, kernel_size=3, stride=3, padding=5, output_padding=2, dilation=1, bias=True, padding_mode='zeros'))\n",
    "\n",
    "tensor4 = torch.rand(1, 1, 1)\n",
    "print(compare_results(tensor4, in_channels=1, out_channels=1, kernel_size=1, stride=1, padding=0, output_padding=0, dilation=1, bias=True, padding_mode='zeros'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительное задание:\n",
    "#### Реализовать алгоритм работы транспонированной свертки, через алгоритм двумерной свертки, реализованный в первой лабораторной. Необходимо перерассчитать входные параметры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1702066167245,
     "user": {
      "displayName": "Adlisse",
      "userId": "09888939323989321551"
     },
     "user_tz": -180
    },
    "id": "LCvwKIdB9EV3"
   },
   "outputs": [],
   "source": [
    "def myfunc_Conv2D(input, \n",
    "                  in_channels, \n",
    "                  out_channels, \n",
    "                  kernel_size,\n",
    "                  transp_stride=1, \n",
    "                  padding=0, \n",
    "                  dilation=1, \n",
    "                  bias=True,\n",
    "                  padding_mode='zeros'):\n",
    "  stride = 1\n",
    "\n",
    "  pad = kernel_size - 1\n",
    "  result_input = []\n",
    "  for matr in input:\n",
    "    zero_tensor = np.zeros((((matr.shape[0] - 1) * (transp_stride) + 1), ((matr.shape[1] - 1) * (transp_stride) + 1)))\n",
    "    for a in range(0, zero_tensor.shape[0], transp_stride):\n",
    "      for b in range(0, zero_tensor.shape[1], transp_stride):\n",
    "        zero_tensor[a][b] = matr[a // (transp_stride)][b // (transp_stride)]\n",
    "\n",
    "    pad_matr = np.pad(zero_tensor, pad_width=pad, mode='constant')\n",
    "    result_input.append(pad_matr)\n",
    "  input = torch.tensor(result_input)\n",
    "\n",
    "  if bias:\n",
    "    bias_val = torch.rand(out_channels)\n",
    "  else:\n",
    "    bias_val = torch.zeros(out_channels)\n",
    "    \n",
    "  match padding_mode:\n",
    "    case 'zeros':\n",
    "      pad = torch.nn.ZeroPad2d(padding)\n",
    "      input = pad(input)\n",
    "    case 'reflect':\n",
    "      pad = torch.nn.ReflectionPad2d(padding)\n",
    "      input = pad(input)\n",
    "    case 'replicate':\n",
    "      pad = torch.nn.ReplicationPad2d(padding)\n",
    "      input = pad(input)\n",
    "    case 'circular':\n",
    "      pad = torch.nn.CircularPad2d(padding)\n",
    "      input = pad(input)\n",
    "\n",
    "  weights = np.array(torch.rand(out_channels, in_channels, kernel_size, kernel_size))\n",
    "\n",
    "  weights_for_transpose = []\n",
    "  for j in range(out_channels):\n",
    "    weights_in = []\n",
    "    for i in range(in_channels):\n",
    "      weights_in.append(np.flip(np.array(weights[j][i])))\n",
    "    weights_for_transpose.append(weights_in)\n",
    "\n",
    "  weights_for_transpose = torch.tensor(weights_for_transpose)\n",
    "  weights_for_transpose = weights_for_transpose.reshape(in_channels, out_channels, kernel_size, kernel_size)\n",
    "\n",
    "  res_tensor = []\n",
    "  for l in range(out_channels):\n",
    "    feature_map = np.array([])\n",
    "    for i in range(0, input.shape[1] - ((weights.shape[2] - 1) * dilation + 1) + 1, stride):\n",
    "      for j in range(0, input.shape[2] - ((weights.shape[3] - 1) * dilation + 1) + 1, stride):\n",
    "        summa = 0\n",
    "        for c in range(in_channels):\n",
    "          val = input[c][i:i + (weights.shape[2] - 1) * dilation + 1:dilation,\n",
    "                          j:j + (weights.shape[3] - 1) * dilation + 1:dilation]\n",
    "          mini_sum = (val * weights[l][c]).sum()\n",
    "          summa = summa + mini_sum\n",
    "        feature_map = np.append(feature_map, float(summa + bias_val[l]))\n",
    "    res_tensor.append(feature_map.reshape((input.shape[1] - ((weights.shape[2] - 1) * dilation + 1)) // stride + 1,\n",
    "                                          (input.shape[2] - ((weights.shape[3] - 1) * dilation + 1)) // stride + 1))\n",
    "\n",
    "  return np.array(res_tensor), torch.tensor(np.array(weights_for_transpose)), torch.tensor(np.array(bias_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1702066167246,
     "user": {
      "displayName": "Adlisse",
      "userId": "09888939323989321551"
     },
     "user_tz": -180
    },
    "id": "Wdx7_p2g9EV4"
   },
   "outputs": [],
   "source": [
    "tensor1 = torch.rand(3, 5, 6)\n",
    "tensor2 = torch.rand(1, 28, 28)\n",
    "tensor3 = torch.rand(7, 10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, kernel, bias_val = myfunc_Conv2D(tensor1,in_channels=3, out_channels=1, kernel_size=3, transp_stride=2, bias=True,)\n",
    "torchFunction = torch.nn.ConvTranspose2d(in_channels=3, out_channels=1, kernel_size=3, stride=2, bias=True,)\n",
    "torchFunction.weight.data = kernel\n",
    "torchFunction.bias.data = bias_val\n",
    "myResult = str(np.round(result, 2))\n",
    "torchResult = str(np.round(np.array(torchFunction(tensor1).data), 2))\n",
    "torchResult == myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, kernel, bias_val = myfunc_Conv2D(tensor2,in_channels=1, out_channels=2, kernel_size=4, transp_stride=3, bias=True)\n",
    "torchFunction = torch.nn.ConvTranspose2d(in_channels=1, out_channels=2, kernel_size=4, stride=3, bias=True)\n",
    "torchFunction.weight.data = kernel\n",
    "torchFunction.bias.data = bias_val\n",
    "myResult = str(np.round(result, 2))\n",
    "torchResult = str(np.round(np.array(torchFunction(tensor2).data), 2))\n",
    "torchResult == myResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, kernel, bias_val = myfunc_Conv2D(tensor3, in_channels=7, out_channels=1, kernel_size=3, transp_stride=5, bias=True)\n",
    "torchFunction = torch.nn.ConvTranspose2d(in_channels=7, out_channels=1, kernel_size=3, stride=5, bias=True)\n",
    "torchFunction.weight.data = kernel\n",
    "torchFunction.bias.data = bias_val\n",
    "myResult = str(np.round(result, 2))\n",
    "torchResult = str(np.round(np.array(torchFunction(tensor3).data), 2))\n",
    "torchResult == myResult"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
